---
title: "Big Data Pipeline Cheatsheet for AWS, Azure, and Google Cloud"
description: "Big data pipeline cheatsheet for AWS, Azure, and Google Cloud."
image: "https://assets.bytebytego.com/diagrams/0086-big-data-pipeline-cheatsheet-for-aws-azure-and-gcp.png"
createdAt: "2024-03-14"
draft: false
categories:
  - cloud-distributed-systems
tags:
  - "Big Data"
  - "Cloud Computing"
---

![](https://assets.bytebytego.com/diagrams/0086-big-data-pipeline-cheatsheet-for-aws-azure-and-gcp.png)

Each platform offers a comprehensive suite of services that cover the entire lifecycle:

*   Ingestion: Collecting data from various sources

*   Data Lake: Storing raw data

*   Computation: Processing and analyzing data

*   Data Warehouse: Storing structured data

*   Presentation: Visualizing and reporting insights

AWS uses services like Kinesis for data streaming, S3 for storage, EMR for processing, RedShift for warehousing, and QuickSight for visualization.

Azureâ€™s pipeline includes Event Hubs for ingestion, Data Lake Store for storage, Databricks for processing, Cosmos DB for warehousing, and Power BI for presentation.

GCP offers PubSub for data streaming, Cloud Storage for data lakes, DataProc and DataFlow for processing, BigQuery for warehousing, and Data Studio for visualization.
