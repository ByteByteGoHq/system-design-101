<p>
  <a href="https://blog.bytebytego.com/?utm_source=site"><img src="../images/banner.jpg" /> </a>
</p>

<p align="center">
  „Äê
  <a href="https://www.youtube.com/channel/UCZgt6AzoyjslHTC9dz0UoTw">
    üë®üèª‚Äçüíª YouTube
  </a> | 
  <a href="https://blog.bytebytego.com/?utm_source=site">
    üìÆ Newsletter
  </a> „Äë
</p>

<a href="https://trendshift.io/repositories/3709" target="_blank"><img src="https://trendshift.io/api/badge/repositories/3709" alt="ByteByteGoHq%2Fsystem-design-101 | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>

# System Design 101

Explicando sistemas complexos com visuais e termos simples.

Seja que voc√™ esteja se preparando para uma Entrevista de Design de Sistemas ou simplesmente deseja entender como sistemas funcionam por baixo do cap√¥, esperamos que este reposit√≥rio possa te ajudar.

# Tabela de Conte√∫dos

<!-- TOC toc.levels=2 -->

- [System Design 101](#system-design-101)
- [Tabela de Conte√∫dos](#tabela-de-conte√∫dos)
  - [Protoc√≥los de Comunica√ß√£o](#protoc√≥los-de-comunica√ß√£o)
    - [REST API vs. GraphQL](#rest-api-vs-graphql)
    - [Como o gRPC funciona?](#como-o-grpc-funciona)
    - [O que √© um webhook?](#o-que-√©-um-webhook)
    - [Como melhorar a performance de uma API?](#como-melhorar-a-performance-de-uma-api)
    - [HTTP 1.0 -\> HTTP 1.1 -\> HTTP 2.0 -\> HTTP 3.0 (QUIC)](#http-10---http-11---http-20---http-30-quic)
    - [SOAP vs REST vs GraphQL vs RPC](#soap-vs-rest-vs-graphql-vs-rpc)
    - [Code First vs. API First](#code-first-vs-api-first)
    - [C√≥digos de status HTTP](#c√≥digos-de-status-http)
    - [O que faz um API gatway?](#o-que-faz-um-api-gatway)
    - [Como projetar APIs seguras e efetivas?](#como-projetar-apis-seguras-e-efetivas)
    - [Encapsula√ß√£o TCP/IP](#encapsula√ß√£o-tcpip)
    - [Por que o Nginx √© chamado de uma proxy "reversa"?](#por-que-o-nginx-√©-chamado-de-uma-proxy-reversa)
    - [Quais s√£o os algoritmos de distribui√ß√£o de carga comuns?](#quais-s√£o-os-algoritmos-de-distribui√ß√£o-de-carga-comuns)
    - [URL, URI, URN - Voc√™ sabe a difer√™n√ßa?](#url-uri-urn---voc√™-sabe-a-difer√™n√ßa)
  - [CI/CD](#cicd)
    - [Pipeline CI/CD Explicado em Termos Simples](#pipeline-cicd-explicado-em-termos-simples)
    - [Netflix Stack Tecnol√≥gico (Pipeline de CI/CD)](#netflix-stack-tecnol√≥gico-pipeline-de-cicd)
  - [Pad√µes de Arquitetura](#pad√µes-de-arquitetura)
    - [MVC, MVP, MVVM, MVVM-C, e VIPER](#mvc-mvp-mvvm-mvvm-c-e-viper)
    - [18 Padr√µes de Design Essenciais Que Todo Desenvolvedor Deve Conhecer](#18-padr√µes-de-design-essenciais-que-todo-desenvolvedor-deve-conhecer)
  - [Bancos de Dados](#bancos-de-dados)
    - [Um guia pr√°tico de diferentes bancos de dados em servi√ßos de nuvem](#um-guia-pr√°tico-de-diferentes-bancos-de-dados-em-servi√ßos-de-nuvem)
    - [8 Estruturas de Dados que Impulsionam seus Bancos de Dados](#8-estruturas-de-dados-que-impulsionam-seus-bancos-de-dados)
    - [Como um comando SQL √© executado no Banco de Dados?](#como-um-comando-sql-√©-executado-no-banco-de-dados)
    - [Teorema CAP](#teorema-cap)
    - [Tipos de Mem√≥ria e Armazenamento](#tipos-de-mem√≥ria-e-armazenamento)
    - [Visualizando uma consulta SQL](#visualizando-uma-consulta-sql)
    - [Linguagem SQL](#linguagem-sql)
  - [Cache](#cache)
    - [Data is cached everywhere](#data-is-cached-everywhere)
    - [Why is Redis so fast?](#why-is-redis-so-fast)
    - [How can Redis be used?](#how-can-redis-be-used)
    - [Top caching strategies](#top-caching-strategies)
  - [Microservice architecture](#microservice-architecture)
    - [What does a typical microservice architecture look like?](#what-does-a-typical-microservice-architecture-look-like)
    - [Microservice Best Practices](#microservice-best-practices)
    - [What tech stack is commonly used for microservices?](#what-tech-stack-is-commonly-used-for-microservices)
    - [Why is Kafka fast](#why-is-kafka-fast)
  - [Payment systems](#payment-systems)
    - [How to learn payment systems?](#how-to-learn-payment-systems)
    - [Why is the credit card called ‚Äúthe most profitable product in banks‚Äù? How does VISA/Mastercard make money?](#why-is-the-credit-card-called-the-most-profitable-product-in-banks-how-does-visamastercard-make-money)
    - [How does VISA work when we swipe a credit card at a merchant‚Äôs shop?](#how-does-visa-work-when-we-swipe-a-credit-card-at-a-merchants-shop)
    - [Payment Systems Around The World Series (Part 1): Unified Payments Interface (UPI) in India](#payment-systems-around-the-world-series-part-1-unified-payments-interface-upi-in-india)
  - [DevOps](#devops)
    - [DevOps vs. SRE vs. Platform Engineering. What is the difference?](#devops-vs-sre-vs-platform-engineering-what-is-the-difference)
    - [What is k8s (Kubernetes)?](#what-is-k8s-kubernetes)
    - [Docker vs. Kubernetes. Which one should we use?](#docker-vs-kubernetes-which-one-should-we-use)
    - [How does Docker work?](#how-does-docker-work)
  - [GIT](#git)
    - [How Git Commands work](#how-git-commands-work)
    - [How does Git Work?](#how-does-git-work)
    - [Git merge vs. Git rebase](#git-merge-vs-git-rebase)
  - [Cloud Services](#cloud-services)
    - [A nice cheat sheet of different cloud services (2023 edition)](#a-nice-cheat-sheet-of-different-cloud-services-2023-edition)
    - [What is cloud native?](#what-is-cloud-native)
  - [Developer productivity tools](#developer-productivity-tools)
    - [Visualize JSON files](#visualize-json-files)
    - [Automatically turn code into architecture diagrams](#automatically-turn-code-into-architecture-diagrams)
  - [Linux](#linux)
    - [Linux file system explained](#linux-file-system-explained)
    - [18 Most-used Linux Commands You Should Know](#18-most-used-linux-commands-you-should-know)
  - [Security](#security)
    - [How does HTTPS work?](#how-does-https-work)
    - [Oauth 2.0 Explained With Simple Terms.](#oauth-20-explained-with-simple-terms)
    - [Top 4 Forms of Authentication Mechanisms](#top-4-forms-of-authentication-mechanisms)
    - [Session, cookie, JWT, token, SSO, and OAuth 2.0 - what are they?](#session-cookie-jwt-token-sso-and-oauth-20---what-are-they)
    - [How to store passwords safely in the database and how to validate a password?](#how-to-store-passwords-safely-in-the-database-and-how-to-validate-a-password)
    - [Explaining JSON Web Token (JWT) to a 10 year old Kid](#explaining-json-web-token-jwt-to-a-10-year-old-kid)
    - [How does Google Authenticator (or other types of 2-factor authenticators) work?](#how-does-google-authenticator-or-other-types-of-2-factor-authenticators-work)
  - [Real World Case Studies](#real-world-case-studies)
    - [Netflix's Tech Stack](#netflixs-tech-stack)
    - [Twitter Architecture 2022](#twitter-architecture-2022)
    - [Evolution of Airbnb‚Äôs microservice architecture over the past 15 years](#evolution-of-airbnbs-microservice-architecture-over-the-past-15-years)
    - [Monorepo vs. Microrepo.](#monorepo-vs-microrepo)
    - [How will you design the Stack Overflow website?](#how-will-you-design-the-stack-overflow-website)
    - [Why did Amazon Prime Video monitoring move from serverless to monolithic? How can it save 90% cost?](#why-did-amazon-prime-video-monitoring-move-from-serverless-to-monolithic-how-can-it-save-90-cost)
    - [How does Disney Hotstar capture 5 Billion Emojis during a tournament?](#how-does-disney-hotstar-capture-5-billion-emojis-during-a-tournament)
    - [How Discord Stores Trillions Of Messages](#how-discord-stores-trillions-of-messages)
    - [How do video live streamings work on YouTube, TikTok live, or Twitch?](#how-do-video-live-streamings-work-on-youtube-tiktok-live-or-twitch)
  - [License](#license)

<!-- /TOC -->

## Protoc√≥los de Comunica√ß√£o

Estilos de arquiteturas definem como os diferentes componentes de uma interface de programa√ß√£o de aplica√ß√µes (API, _Application Programming Interface_) interagem entre si. Como resultado, eles garantem efici√™ncia, confiabilidade e facilidade de integra√ß√£o com outros sistemas, proporcionando uma abordagem padr√£o para projetar e construir APIs. Aqui est√£o os estilos mais utilizados:

<p>
  <img src="../images/api-architecture-styles.png" style="width: 640px">
</p>

- SOAP:

  Amadurecido, abrangente, baseado em XML

  Ideal para aplica√ß√µes empresariais

- RESTful:

  Popular, f√°cil implementa√ß√£o, m√©todos HTTP

  Ideal para servi√ßos web

- GraphQL:

  Linguagem de Consulta, requisita dados espec√≠ficos

  Reduz sobrecarga de rede, respostas mais r√°pidas

- gRPC:

  Moderno, alta performance, Protocol Buffers

  Adequado para arquiteturas de microsservi√ßos

- WebSocket:

  Tempo-real, bidirecional, conex√µes persistentes

  Perfeito para troca de dados de baixa lat√™ncia

- Webhook:

  Orientado a eventos, chamadas de retorno HTTP, ass√≠ncrono

  Notifica o sistema sobre a ocorr√™ncia de um evento

### REST API vs. GraphQL

Quando se trata de design de APIs, REST e GraphQL tem suas for√ßas e fraquezas.

O diagrama abaixo mostra uma r√°pida compara√ß√£o entre REST e GraphQL.

<p>
  <img src="../images/graphQL.jpg">
</p>

REST

- Utiliza m√©todos HTTP padr√µes como GET, POST, PUT, DELETE para opera√ß√µes CRUD.
- Funciona bem quando voc√™ precisa de uma interface simples e uniforme entre servi√ßos/aplica√ß√µes separadas.
- Estrat√©gias de cache s√£o de simples implementa√ß√£o.
- O lado negativo √© que pode levar diversas viagens de ida-e-volta para montar os dados relacionados de endpoints separados.

GraphQL

- Fornece um √∫nico ponto para clientes realizarem consultas em qualquer dado que precisem.
- Os clientes especificam os campos exatos necess√°rios em consultas aninhadas, e o servidor retorna cargas otimizadas contendo apenas esses campos.
- Suporta Mutations para modificar dados e Subscriptions para notifica√ß√µes em tempo real.
- √ìtima para agregar dados de diversas fontes e se adapta bem com requeritos requisitos de frontend que evoluem rapidamente.
- No entanto, isso transfere a complexidade para o lado do cliente e pode permitir consultas abusivas se n√£o forem devidamente protegidas.
- Estrat√©gias de Caching podem ser mais complexas que REST.

A melhor escolha entre REST e GraphQL depende nos requisitos espec√≠ficos da aplica√ß√£o e time de desenvolvimento. GraphQL √© uma boa op√ß√£o para necessidades frontend complexas ou que mudam frequentemente, enquanto REST √© adequado para aplica√ß√µes onde contratos simples e consistentes s√£o preferidos.

Nenhuma abordagem dessas APIs √© uma solu√ß√£o milagrosa. Avaliar cuidadosamente os requisitos e as compensa√ß√µes √© importante para escolher o estilo certo. Tanto REST quanto GraphQL s√£o op√ß√µes v√°lidas para expor dados e impulsionar aplica√ß√µes modernas.

### Como o gRPC funciona?

RCP (Chamada de Procedimento Remota, _Remote Procedure Call_) √© chamada de "**remota**" pois habilita comunica√ß√£o entre servi√ßos quando estes s√£o implantados em servidores sob a arquitetura de microsservi√ßos. Do ponto de vista do usu√°rio, ele age como uma chamada de fun√ß√£o local.

O diagrama abaixo ilustra o fluxo geral de dados para o **gRPC**.

<p>
  <img src="../images/grpc.jpg">
</p>

Passo 1: Uma chamada REST parte do cliente. O corpo da requisi√ß√£o √© geralmetne em formato JSON.

Passo 2 - 4: O Servi√ßo de Pedidos (_Order Service_, que √© o cliente gRPC) recebe a chamada REST, a transforma e realiza uma chamada RPC para o Servi√ßo de Pagamentos (_Payment Service_). O gRPC codifica o stub do cliente em um formato bin√°rio e o envia para a camada de transporte de baixo n√≠vel.

Passp 5: O gRPC envia os pacotes pela rede via HTTP2. Por conta da codifica√ß√£o bin√°ria e otimiza√ß√µes de rede, o gRPC √© dito ser 5x mais r√°pido que JSON.

Passo 6 - 8: O Servi√ßo de Pagamentos (_Payment Service_, servidor gRPC) recebe os pacotes da rede, os decodifica e invoca a aplica√ß√£o do servidor.

Passos 9 - 11: O resultado √© retornado pela aplica√ß√£o do servidor, codificado e enviado para a camada de transporte.

Passos 12 - 14: O Servi√ßo de Pedidos (_Order Service_, cliente gRPC) recebe os pacotes, os decodifica e envia o resultado para a aplica√ß√£o cliente.

### O que √© um webhook?

O diagrama abaixo mostra uma compara√ß√£o entre Polling e Webhook.

<p>
  <img src="../images/webhook.jpeg" style="width: 680px" />
</p>

Assuma que estamos rodando um website de eCommerce. Os clientes enviam ordens para o Servi√ßo de Ordems pelo API gateway, que aciona o Servi√ßo de Pagamento para transa√ß√µes de pagament. O Servi√ßo de Pagamento fala com um provedor de servi√ßos de pagamento (PSP) para completar as transa√ß√µes.

H√° duas forms de lidar comcomunica√ß√µes com um PSP.

**1. Polling Curto (Short Polling)**

Depois de enviar um pedido de pagamento para o PSP, o servi√ßo de pagamento fica perguntando ao PSP sobre o status do pagamento. Depois de alguns rounds, o PSP finalmente retorna o status.

Polling curto possui duas desvantagens:

- Relizar polling constante a respeito do status consome recursos do Servi√ßo de Pagamento.
- O Servi√ßo Externo se comuica diretamente com o Servi√ßo de Pagamento, criando vulnerabilidades.

**2. Webhook**

N√≥s podemos registrar um webhook com o Servi√ßo Externo. Isso √©: Me avise neste URL quando voc√™ tiver alguma atualiza√ß√£o da requisi√ß√£o. Quando o PSP completaqr o processamento, ele ir√° invocar uma requisi√ß√£o HTTP para atualizar o status do pagamento.

Desta forma, o paradigma da programa√ß√£o mudou, quando o Servi√ßo de Pagamento n√£o precisa mais desperdi√ßar recursos fazendo polling no status de pagamento.

Mas e se o PSP n√£o nos retorna? Podemos fazer uma tarefa/servi√ßo de limpeza para checar o status de pagamento a cada hora.

Webhooks s√£o geralmente referidos como APIs reversos ou push APIs, j√° que o servidor envia requisi√ß√µes HTTP para o cliente. N√≥s precisamos prestar aten√ß√£o a 3 pontos quando utilizamos webhooks:

1. Precisamos projetar uma API adequada para ser chamada pelo servi√ßo externo.
2. Precisamos configurar regras adequadas para o API gateway por raz√µes de seguran√ßa.
3. Precisamos registrar a URL correta no Servi√ßo Externo.

### Como melhorar a performance de uma API?

O diagrama abaixo mostra 5 truques comuns para melhorar a performance de uma API.

<p>
  <img src="../images/api-performance.jpg">
</p>

Pagina√ß√£o

Esta √© uma otimiza√ß√£o comun quando o tamanho do resultado √© muito grande. Os resultados s√£o transmitidos de volta para o cliete para melhorar a reponsividade do servi√ßo.

Logging Ass√≠ncrono

O log s√≠ncrono lida com o disco a cada chamada e pode diminuir a velocidade do sistema. O log ass√≠ncrono envia os logs primeiro para um buffer sem bloqueio e retorna imediatamente. Os logs ser√£o periodicamente gravados no disco. Isso reduz significativamente a sobrecarga de E/S (Entrada/Sa√≠da).

Caching

N√≥s podemos armazenar dados frequentemente acessados num cache. O cliente pode realizar uma consulta no cache primeiramente, ao inv√©s de ir direto ao banco de dados. Se ocorrer um cache miss, o cliente deve realizar a consulta ao banco. Caches como Redis armazenam dados em mem√≥ria, deixando o acesso aos dados muito mais r√°pido que em um banco de dados.

Compress√£o da Carga √ötil

As slicita√ß√µes e respostas podem ser comprimidas utilizando gzip etc para que os dados transmitidos tenham um tamanho menor. Isso acelera o upload e download.

Pool de Conex√µes

Ao acessar recursos, n√≥s precisamos carregar dados do banco de dados. Abrir e fechar conex√µes com o baco adiciona uma sobrecarga significativa. Portanto podemos nos conectar por um pool de conex√µes abertas. O pool de conex√µes √© respons√°vel por gerenciar o ciclo de vida da conex√£o.

### HTTP 1.0 -> HTTP 1.1 -> HTTP 2.0 -> HTTP 3.0 (QUIC)

Quais problemas s√£o resolvidos por cada gera√ß√£o de HTTP?

O diagrama abaixo ilustra as principais caracter√≠sticas.

<p>
  <img src="../images/http3.jpg" />
</p>

- HTTP 1.0 foi finalizado e totalmente documentado em 1996. Cada solicita√ß√£o ao mesmo servidor requer uma conex√£o TCP separada.

- HTTP 1.1 foi publicado em 1997. Uma conex√£o TCP pode ser deixada aberta para reutiliza√ß√£o (conex√£o persistente), mas n√£o resolve o problema do bloqueio HOL (head-of-line).

  Bloqueio HOL - quando o n√∫mero de solicita√ß√µes paralelas permitidas no navegador √© esgotado, solicita√ß√µes subsequentes precisam aguardar as anteriores serem conclu√≠das.

- HTTP 2.0 foi publicado em 2015. Ele aborda o problema HOL por meio do multiplexamento de solicita√ß√µes, o que elimina o bloqueio HOL na camada de aplica√ß√£o, mas HOL ainda existe na camada de transporte (TCP).

  Como voc√™ pode ver no diagrama, o HTTP 2.0 introduziu o conceito de "streams" HTTP: uma abstra√ß√£o que permite multiplexar diferentes trocas de HTTP na mesma conex√£o TCP. Cada stream n√£o precisa ser enviado em ordem.

- HTTP 3.0 teve seu rascunho publicado em 2020. Ele √© o sucessor proposto do HTTP 2.0. Utiliza o QUIC em vez do TCP como protocolo de transporte subjacente, removendo assim o bloqueio HOL na camada de transporte.

  O QUIC √© baseado no UDP. Ele introduz streams como cidad√£os de primeira classe na camada de transporte. Os streams QUIC compartilham a mesma conex√£o QUIC, portanto, n√£o s√£o necess√°rios handshake adicionais e in√≠cios lentos para criar novas conex√µes, mas os streams QUIC s√£o entregues independentemente, de modo que, na maioria dos casos, a perda de pacotes que afeta uma stream n√£o afeta as outras.

### SOAP vs REST vs GraphQL vs RPC

O diagrama abaixo ilustra a linha do tempo da API e a compara√ß√£o de estilos de API.

Ao longo do tempo, diferentes estilos arquiteturais de API s√£o lan√ßados. Cada um deles tem suas pr√≥prias t√©cnicas para padronizar a troca de dados.

Voc√™ pode conferir os casos de uso de cada estilo no diagrama.

<p>
  <img src="../images/SOAP vs REST vs GraphQL vs RPC.jpeg" />
</p>

### Code First vs. API First

O diagrama abaixo mostra as diferen√ßas entre o desenvolvimento Code First e o desenvolvimento API First. Por que queremos considerar o design API First?

<p>
  <img src="../images/api_first.jpg" style="width: 680px" />
</p>

- Microsservi√ßos aumentar a complexidade do sistema e precisamos separar servi√ßos para servir fun√ß√µes diferentes no sistema. Embora esse tipo de arquitetura facilite o desacoplamento e a segrega√ß√£o de responsabilidades, √© necess√°rio lidar com as diversas comunica√ß√µes entre os servi√ßos.

√â melhor analisar a complexidade do sistema antes de escrever o c√≥digo e definir cuidadosamente os limites dos servi√ßos.

- Equipes funcionais separadas precisam falar a mesma linguagem, e as equipes funcionais dedicadas s√£o respons√°veis apenas por seus pr√≥prios componentes e servi√ßos. Recomenda-se que a organiza√ß√£o fale a mesma linguagem por meio do design de API.

Podemos simular solicita√ß√µes e respostas para validar o design da API antes de escrever o c√≥digo.

- Melhora a qualidade do software e a produtividade do desenvolvedor. Como resolvemos a maioria das incertezas no in√≠cio do projeto, o processo de desenvolvimento √© mais suave, e a qualidade do software √© significativamente aprimorada.

Os desenvolvedores ficam satisfeitos com o processo, pois podem se concentrar no desenvolvimento funcional em vez de lidar com mudan√ßas repentinas.

A possibilidade de surpresas no final do ciclo de vida do projeto √© reduzida.

Como projetamos a API primeiro, os testes podem ser planejados enquanto o c√≥digo est√° sendo desenvolvido. De certa forma, tamb√©m temos o TDD (Design Orientado a Testes) ao usar o desenvolvimento API first.

### C√≥digos de status HTTP

<p>
  <img src="../images/http-status-code.jpg" style="width: 540px" />
</p>

Os c√≥digos de resposta para o HTTP s√£o divididos em cinco categorias:

Informativos (100-199)
Sucesso (200-299)
Redirecionamento (300-399)
Erro do Cliente (400-499)
Erro do Servidor (500-599)

### O que faz um API gatway?

O diagrama abaixo ilustra as principais caracter√≠sticas.

<p>
  <img src="../images/api_gateway.jpg" style="width: 520px" />
</p>

Passo 1 - O cliente enviar uma requisi√ß√£o HTTP para o API gateway.

Passo 2 - O API gateway analisa e valida os atributos na solicita√ß√£o HTTP.

Passo 3 - O API gateway verifica a lista de permiss√µes/nega√ß√µes.

Passo 4 - O API gateway se comunica com um provedor de identidade para autentica√ß√£o e autoriza√ß√£o.

Passo 5 - As regras de limita√ß√£o de taxa s√£o aplicadas √† solicita√ß√£o. Se estiver acima do limite, a solicita√ß√£o √© rejeitada.

Passos 6 e 7 - Agora que a solicita√ß√£o passou pelas verifica√ß√µes b√°sicas, o API gateway encontra o servi√ßo relevante para rotear por meio de correspond√™ncia de caminho.

Passo 8 - O API gateway transforma a requisi√ß√£o no protocolo apropriado e o envia aos microsservi√ßos do backend.

Passos 9-12: O API agteway pode lidar adequadamente com erros e tratar falhas se o erro levar mais tempo para se recuperar (circuit break). Tamb√©m pode usar a pilha ELK (Elastic-Logstash-Kibana) para registro e monitoramento. √Äs vezes, s√£o armazenados dados em cache no gateway de API.

### Como projetar APIs seguras e efetivas?

O diagrama abaixo ilustra os designs t√≠picos de API com um exemplo de carrinho de compras.

<p>
  <img src="../images/safe-apis.jpg" />
</p>

Observe que o design da API n√£o se resume apenas ao design do caminho do URL. Na maioria das vezes, precisamos escolher nomes apropriados para os recursos, identificadores e padr√µes de caminho. √â igualmente importante projetar campos de cabe√ßalho HTTP adequados ou criar regras eficazes de limita√ß√£o de taxa dentro do API gateway.

### Encapsula√ß√£o TCP/IP

Como os dados s√£o enviados pela rede? Por que n√≥s precisamos de tantas camadas no modelo OSI?

O diagrama abaixo mostra como dados s√£o encapsulados e desencapsulados ao trasmitidos pela rede.

<p>
  <img src="../images/osi model.jpeg" />
</p>

Passo 1: Quando o Dispositivo A envia dados para o Dispositivo B pela rede via protocolo HTTP, √© primeiro adicionado um cabe√ßalho HTTP na camada de aplica√ß√£o.

Passo 2: Em seguida, √© adicionado um cabe√ßalho TCP ou UDP aos dados. Eles s√£o encapsulados em segmentos TCP na camada de transporte. O cabe√ßalho cont√©m a porta de origem, a porta de destino e o n√∫mero de sequ√™ncia.

Passo 3: Os segmentos s√£o ent√£o encapsulados com um cabe√ßalho IP na camada de rede. O cabe√ßalho IP cont√©m os endere√ßos IP de origem/destino.

Passo 4: O datagrama IP √© adicionado a um cabe√ßalho MAC na camada de enlace de dados, com endere√ßos MAC de origem/destino.

Passo 5: Os quadros encapsulados s√£o enviados para a camada f√≠sica e transmitidos pela rede em bits bin√°rios.

Passos 6-10: Quando o Dispositivo B recebe os bits da rede, ele realiza o processo de desencapsulamento, que √© um processo reverso do processo de encapsulamento. Os cabe√ßalhos s√£o removidos camada por camada e, eventualmente, o Dispositivo B pode ler os dados.

Precisamos de camadas no modelo de rede porque cada camada se concentra em suas pr√≥prias responsabilidades. Cada camada pode depender dos cabe√ßalhos para obter instru√ß√µes de processamento e n√£o precisa conhecer o significado dos dados da camada anterior.

### Por que o Nginx √© chamado de uma proxy "reversa"?

O diagrama abaixo mostra as diferen√ßas entre um proxy de encaminhamento (ùêüùê®ùê´ùê∞ùêöùê´ùêù ùê©ùê´ùê®ùê±ùê≤) e um proxy de reverso (ùê´ùêûùêØùêûùê´ùê¨ùêû ùê©ùê´ùê®ùê±ùê≤).

<p>
  <img src="../images/Forward Proxy v.s. Reverse Proxy2x.jpg" style="width: 720px" />
</p>

Uma proxy de encaminhamento √© um servidor que fica entre usu√°rios e dispositivos na internet.

Uma proxy de encaminhamento √© comumente utilizada para:

1. Proteger clientes
2. Burlar restri√ß√µes de navega√ß√£o
3. Bloquear acesso a conte√∫dos espec√≠ficos

Uma proxy reversa √© um servidor que aceita uma requisi√ß√£o de um cliente, direciona a requisi√ß√£o aos servidores web e retorna os resultados para o cliete como se o pr√≥prio servidor proxy tivesse processado a requisi√ß√£o.

Uma proxy reversa √© boa para:

1. Proteger servidores
2. Distribui√ß√£o de Carga
3. Cachear conte√∫do est√°tico
4. Encriptar e decriptar comunica√ß√µes SSL

### Quais s√£o os algoritmos de distribui√ß√£o de carga comuns?

O diagrama abaixo mostra 6 algoritmos comuns.

<p>
  <img src="../images/lb-algorithms.jpg" />
</p>

- Algoritmos est√°ticos

1. Round robin

   As requisi√ß√µes dos clientes s√£o enviadas para diferentes instancias de servi√ßos em uma ordem sequencial. Os servi√ßos s√£o usualmente requeridos a serem stateless.

2. Round-robin pegajoso (_sticky_)

   Este √© uma melhoria do algoritmo de orund-robin. De a primeira requisi√ß√£o de Alice vai para o servi√ßo A, ent√£o as requisi√ß√µes seguintes tamb√©m v√£o para o servi√ßo A.

3. Round-robin ponderado (_weighted_)

   O administrador pode especificar um peso para cada servi√ßo. Os que tiverem um peso maior, lidam com mais requisi√ß√µes que os outros.

4. Hash

   Este algoritmo aplica uma fun√ß√£o hash (de disper√ß√£o) nos IPs ou URLs das requisi√ß√µes. As requisi√ß√µes s√£o roteadas para inst√¢ncias relvantes com base no resultado do resultado da fun√ß√£o hash.

- Dynamic Algorithms

5. Least connections

   A new request is sent to the service instance with the least concurrent connections.

6. Least response time

   A new request is sent to the service instance with the fastest response time.

### URL, URI, URN - Voc√™ sabe a difer√™n√ßa?

O diagrama abaixo mostra uma compara√ß√£o de URL, URI e URN.

<p>
  <img src="../images/url-uri-urn.jpg" />
</p>

- URI

URI significa Idetificador Uniforme de Recursos (_Uniform Resource Identifier_). Ele identifica um recurso l√≥gico ou f√≠sico na web. URL e URN s√£o subtipos de URI. URL localiza um recurso, enquanto URN nomeia um recurso.

Um URI √© composto das seguintes partes:
scheme:[//authority]path[?query][#fragment]

- URL

URL significa Localizador Uniforme de Recurso (_Uniform Resource Locator_), o conceito-chave do HTTP. √â o endere√ßo de um recurso √∫nico na web. Pode ser usado com outros protocolos, como FTP e JDBC.

- URN

URN significa Nome Uniforme de Recurso (_Uniform Resource Name_). Ele usa o esquema urn. URNs n√£o podem ser usados para localizar um recurso. Um exemplo simples fornecido no diagrama √© composto por um namespace e uma string espec√≠fica do namespace.

Se voc√™ deseja obter mais detalhes sobre o assunto, eu recomendaria a [explica√ß√£o do W3C](https://www.w3.org/TR/uri-clarification/).

## CI/CD

### Pipeline CI/CD Explicado em Termos Simples

<p>
  <img src="../images/ci-cd-pipeline.jpg" style="width: 680px" />
</p>

Se√ß√£o 1 - SDLC com CI/CD

O ciclo de vida de desenvolvimento de software (SDLC, _Software Development Life Cycle_) consiste em v√°rias etapas-chave: desenvolvimento, teste, implanta√ß√£o e manuten√ß√£o. CI/CD automatiza e integra essas etapas para possibilitar lan√ßamentos mais r√°pidos e confi√°veis.

Quando o c√≥digo √© enviado para um reposit√≥rio Git, isso aciona um processo automatizado de compila√ß√£o e teste. Casos de teste de ponta a ponta (end-to-end ou e2e) s√£o executados para validar o c√≥digo. Se os testes s√£o bem-sucedidos, o c√≥digo pode ser implantado automaticamente no ambiente de preparo/produ√ß√£o. Se problemas s√£o identificados, o c√≥digo √© enviado de volta para o desenvolvimento para corre√ß√£o de bugs. Essa automa√ß√£o proporciona um feedback r√°pido aos desenvolvedores e reduz o risco de erros em produ√ß√£o.

Se√ß√£o 2 - Diferen√ßa entre CI e CD

Integra√ß√£o Continua (CI, Continous Integrations) automatiza o processo de compila√ß√£o, teste e o processo de implanta√ß√£o. Roda testes quando c√≥digo √© comitado para detec√ß√£o de problemas de integra√ß√£o precocemente. Isso encoraja commits frequentes e feedback r√°pido.

Entrega Cont√≠nua (CD, Continuous Delivery) automatiza processos de lan√ßamento como mudan√ßas de infraestrutura e implanta√ß√£o. Garante que o software possa ser lan√ßado de maneira confi√°vel a qualquer momento por meio de fluxos de trabalho automatizados. A CD tamb√©m pode automatizar etapas de teste manual e aprova√ß√£o necess√°rias antes da implanta√ß√£o em produ√ß√£o.

Se√ß√£o 3 - Pipeline de CI/CD

Um pipeline t√≠pico de CI/CD tem alguns est√°gios conectados:

- O desenvolvedor comita mudan√ßas de c√≥digo para o controle de vers√£o
- O servidor de CI detecta as mudan√ßas e d√° in√≠cio √† compila√ß√£o
- Code √© compilado e testado (unit√°rio e de integra√ß√£o)
- Os resultados s√£o reportados ao desenvolvedor
- No sucesso, artefatos s√£o lan√ßados para o ambiente de preparo (staging)
- Testes adicionais podem ser realizados no ambiente de preparo antes do lan√ßamento
- O sistema de CD lan√ßa mudan√ßas aprovadas para produ√ß√£o

### Netflix Stack Tecnol√≥gico (Pipeline de CI/CD)

<p>
  <img src="../images/netflix-ci-cd.jpg" style="width: 720px" />
</p>

Planejamento: A Engenharia da Netflix utiliza o JIRA para planejamento e o Confluence para documenta√ß√£o.

Codifica√ß√£o: Java √© a linguagem de programa√ß√£o principal para o servi√ßo backend, enquanto outras linguagens s√£o utilizadas para diferentes casos de uso.

Compila√ß√£o: Gradle √© principalmente utilizado para compila√ß√£o, e plugins do Gradle s√£o constru√≠dos para suportar v√°rios casos de uso.

Empacotamento: O pacote e suas depend√™ncias s√£o empacotados em uma Imagem de M√°quina Amazon (AMI, _Amazon Machine Image_) para lan√ßamento.

Testes: Os testes enfatizam o foco da cultura de produ√ß√£o na constru√ß√£o de ferramentas de caos.

Implanta√ß√£o: A Netflix utiliza sua pr√≥pria ferramenta Spinnaker para implanta√ß√£o de rollout de can√°rio.

Monitoramento: As m√©tricas de monitoramento s√£o centralizadas no Atlas, e o Kayenta √© utilizado para detectar anomalias.

Relat√≥rio de Incidentes: Incidentes s√£o despachados de acordo com a prioridade, e o PagerDuty √© utilizado para o tratamento de incidentes.

## Pad√µes de Arquitetura

### MVC, MVP, MVVM, MVVM-C, e VIPER

Esses padr√µes de arquitetura est√£o entre os mais comumente utilizados no desenvolvimento de aplicativos, seja nas plataformas iOS ou Android. Os desenvolvedores os introduziram para superar as limita√ß√µes de padr√µes anteriores. Ent√£o, como eles diferem?

<p>
  <img src="../images/client arch patterns.png" style="width: 720px" />
</p>

- MVC (Modelo-Vis√£o-Controle, _Model View Controller_), o padr√£o mais antigo, de quase 50 anos
- Cada padr√£o possui uma "vis√£o", _view_ (V) respons√°vel por exibir conte√∫do e receber entrada do usu√°rio
- A maioria dos padr√µes incluem um "modelo", _model_ (M) para manusear dados de neg√≥cio
- "Controller", "presenter" e "view-model" s√£o tradutores que atuam como mediadores entre a "view" e o "model" (ou "entity" no padr√£o VIPER).

### 18 Padr√µes de Design Essenciais Que Todo Desenvolvedor Deve Conhecer

Padr√µes s√£o solu√ß√µes reutiliz√°veis para problemas comuns de design, resultando em um processo de desenvolvimento mais linear e eficiente. Eles servem como modelos para construir estruturas de software mais s√≥lidas. Aqui est√£o alguns dos padr√µes mais populares:

<p>
  <img src="../images/18-oo-patterns.png" />
</p>

- F√°brica Abstrata (_Abstract Factory_): Criador de Fam√≠lias - Cria grupos de itens relacionados.
- Construtor (_Builder_): Mestre Lego - Constr√≥i objetos passo a passo, mantendo a cria√ß√£o e a apar√™ncia separadas.
- Prot√≥tipo (_Prototype_): Clone Maker - Cria c√≥pias de exemplos totalmente preparados.
- Singleton: √önico e Exclusivo - Uma classe especial com apenas uma inst√¢cia.
- Adaptador(_Adapter_): Plugue Universal - Conecta coisas com interfaces diferentes.
- Ponte (_Bridge_): Connectador Funcional - Liga como um objeto funciona ao que ele faz.
- Composito (_Composite_): Constutor de √Årvores - Forma uma estruturas semelhantes a √°rvore com partes simples e complexas.
- Decorador (_Decorator_): Customizador - Adiciona funcionalidade a objetos sem alterar seu n√∫cleo.
- Fa√ßada (_Facade_): Tudo em Um - Representa um sistema inteiro com uma √∫nica interface simplificada.
- Peso Mosca (_Flyweight_): Economizador de Espa√ßo - Compartilha itens pequenos e reutiliz√°veis de maneira eficiente.
- Proxy: Ator Substituto - Representa outro objeto, controlando acesso ou a√ß√µes.
- Cadeia de Responsabilidades (_Chain of Responsibility_): Rel√© de Requisi√ß√µes - Passa uma requisi√ß√£o por uma cadeia de objetos at√© que seja tratada.
- Comando (_Command_): Envelopador de Tarefas - Transforma uma solicita√ß√£o em um objeto, pronto para atuar.
- Iterador (_Iterator_): Explora√ß√£o de Cole√ß√µes - Acessa elementos em uma cole√ß√£o, um a um.
- Mediador (_Mediator_): Central de Comunica√ß√µes - Simplifica intera√ß√µes entre classes distintas.
- Lembran√ßa (_Memento_): C√°psula do Tempo - Captura e restaura o estado de um objeto.
- Observador (_Observer_): Emissora de Not√≠cias - Notifica classes sobre mudan√ßas em outros objetos.
- Visitante (_Visitor_): H√≥spede Habilidoso - Adiciona novas opera√ß√µes a uma classe sem alter√°-la.

## Bancos de Dados

### Um guia pr√°tico de diferentes bancos de dados em servi√ßos de nuvem

<p>
  <img src="../images/cloud-dbs2.png" />
</p>

Escolher o banco de dados correto para o seu projeto √© uma tarefa complexa. Muitas op√ß√µes de bancos de dados, cada uma adequada a casos de uso distintos, podem rapidamente levar √† fadiga de decis√µes.

Esperamos que este guia pr√°tico forne√ßa direcionamento de alto n√≠vel para identificar o servi√ßo correto que esteja alinhado com as necessidades do seu projeto e evite poss√≠veis ciladas.

Nota: O Google limitou a documenta√ß√£o para os casos de uso de seus banco de dados. Mesmo que tenhamos feito o nosso melhor para examinar o que estava dispon√≠vel e chegar √† melhor op√ß√£o, algumas das entradas podem precisar de maior precis√£o.

### 8 Estruturas de Dados que Impulsionam seus Bancos de Dados

A resposta ir√° variar dependendo do seu caso de uso. Dados podem ser indexados em mem√≥ria ou em disco. Similarmente, os formatos dos dados variam, como n√∫meros, strings, coordenadas geogr√°ficas etc. O sistema pode ser intensivo em escrita (write-heavy) ou intensivo em leitura (read-heavy). Todos esses fatores afetam a escolha do formato de √≠ndice do banco de dados.

<p>
  <img src="../images/8-ds-db.jpg" />
</p>

A seguir est√£o algumas das estruturas de dados mais populares usadas para indexar dados:

- Skiplist: um tipo comum de √≠ndice em mem√≥ria. Usado no Redis
- √çndice de hash: uma implementa√ß√£o muito comum da estrutura de dados "Mapa" (ou "Cole√ß√£o")
- SSTable: implementa√ß√£o em disco e imut√°vel do "Mapa"
- √Årvore LSM: Skiplist + SSTable. Alta taxa de grava√ß√£o
- B-tree: solu√ß√£o baseada em disco. Desempenho de leitura/grava√ß√£o consistente
- √çndice invertido: usado para indexa√ß√£o de documentos. Usado no Lucene
- √Årvore de sufixos: para pesquisa de padr√µes em strings
- R-tree: pesquisa multidimensional, como encontrar o vizinho mais pr√≥ximo

### Como um comando SQL √© executado no Banco de Dados?

O diagrama abaixo demonstra o processo. Note que a arquitetura de diferentes bancos s√£o diferentes, o diagrama apresenta alguns designs comuns.

<p>
  <img src="../images/sql execution order in db.jpeg" style="width: 580px" />
</p>

Passo 1 - Uma instru√ß√£o SQL √© enviada para o banco de dados por meio de um protocolo de camada de transporte (por exemplo, TCP).

Passo 2 - A instru√ß√£o SQL √© enviada ao analisador (_parser_) de comandos, onde passa por an√°lise sint√°tica e sem√¢ntica, e em seguida, uma √°rvore de consulta √© gerada.

Passo 3 - A √°rvore de consulta √© enviada ao otimizador. O otimizador cria um plano de execu√ß√£o.

Passo 4 - O plano de execu√ß√£o √© enviado ao executor. O executor recupera os dados da execu√ß√£o.

Passo 5 - M√©todos de acesso fornecem a l√≥gica de recupera√ß√£o de dados necess√°ria para a execu√ß√£o, recuperando dados do mecanismo de armazenamento (_storage engine_).

Passo 6 - Os m√©todos de acesso decidem se a instru√ß√£o SQL √© somente leitura. Se a consulta for somente leitura (instru√ß√£o SELECT), ela √© enviada para o gerenciador de buffer para processamento adicional. O gerenciador de buffer procura os dados no cache ou nos arquivos de dados.

Passo 7 - Se a instru√ß√£o for um UPDATE ou INSERT, ela √© enviada para o gerenciador de transa√ß√µes para processamento adicional.

Passo 8 - Durante uma transa√ß√£o, os dados est√£o em modo de bloqueio. Isso √© garantido pelo gerenciador de bloqueio. Ele tamb√©m assegura as propriedades ACID da transa√ß√£o.

### Teorema CAP

O Teorema CAP √© um dos termos mais famosos na ci√™ncia da computa√ß√£o, mas aposto que desenvolvedores diferentes tem interpreta√ß√µes diferentes. Vamos examinar o que √© e por que pode ser confuso.

<p>
  <img src="../images/cap theorem.jpeg" />
</p>

O teorema CAP afirma que um sistema distribu√≠do n√£o pode fornecer mais do que duas destas tr√™s garantias simultaneamente.

**Consist√™ncia**: consist√™ncia significa que todos os clientes enxergam os mesmos dados ao mesmo tempo, n√£o importando em qual n√≥ eles se conectam.

**Disponibilidade**: disponibilidade significa que qualquer cliente que realizar uma requisi√ß√£o de dados ter√° uma resposta, mesmo que alguns n√≥s n√£o estejam de p√©.

**Toler√¢ncia de Parti√ß√£o**: uma parti√ß√£o indica uma quebra na comunica√ß√£o entre dois n√≥s. Uma toler√¢ncia de parti√ß√£o significa que o sistema continua em opera√ß√£o apesar de parti√ß√µes de redes.

A formula√ß√£o "2 de 3" pode ser √∫til, **mas essa simplifica√ß√£o pode ser enganosa**.

1. Escolher um banco de dados n√£o √© f√°cil. Justificar sua escolha puramente no teorema CAP n√£o √© o suficiente. Por exemplo, companhias n√£o escolhem Cassandra para aplicativos de cat simplesmente por ser um sistema AP. H√° uma lista de caracter√≠sticas que tornam uma op√ß√£o boa para armazenamento de mensagens de chat. Precisamos cavar mais fundo.

2. "CAP pro√≠be apenas uma pequena parte do espa√ßo de design: disponibilidade e consist√™ncia perfeitas na presen√ßa de parti√ß√µes, que s√£o raras". Citado do artigo: CAP Twelve Years Later: How the "Rules" Have Changed.

3. O teorema trata de disponibilidade e consist√™ncia de 100%. Uma discuss√£o mais realista envolveria as compensa√ß√µes entre lat√™ncia e consist√™ncia quando n√£o h√° parti√ß√£o de rede. Consulte o teorema PACELC para obter mais detalhes.

**O teorema CAP √© de fato √∫til?**

Acredito que ainda √© √∫til por abrir nossas mentes para um novo conjunto de discuss√µes sobre compensa√ß√µes, mas √© apenas uma parte da hist√≥ria. Precisamos nos aprofundar para esolcher o banco de dados correto.

### Tipos de Mem√≥ria e Armazenamento

<p>
  <img src="../images/Types_of_Memory_and_Storage.jpeg" style="width: 420px" />
</p>

### Visualizando uma consulta SQL

<p>
  <img src="../images/sql-execution-order.jpg" style="width: 580px" />
</p>

As instru√ß√µes SQL s√£o executadas pelo sistema do banco de dados em v√°rias etapas, incluindo:

- Analisando a instru√ß√£o SQL e verificando sua validade
- Transformando o SQL em uma representa√ß√£o interna, como √°lgebra relacional
- Otimizando a representa√ß√£o interna e criando um plano de execu√ß√£o que utiliza informa√ß√µes de √≠ndices
- Executando o plano e retornando os resultados

A execu√ß√£o do SQL √© altamente complexa e envolve muitas considera√ß√µes, tais como:

- O uso de √≠ndices e caches
- A ordem de jun√ß√µes de tabelas
- Controle de concorr√™ncia
- Gerenciamento de transa√ß√µes

### Linguagem SQL

In 1986, SQL (Structured Query Language) became a standard. Over the next 40 years, it became the dominant language for relational database management systems. Reading the latest standard (ANSI SQL 2016) can be time-consuming. How can I learn it?

Em 1986, SQL (Linguagem de Busca Estruturada, _Structured Query Language_) se tornou um padr√£o. Ao longo os pr√≥ximos 40 anos, ela se tornou a linguagem dominante para sistemas de manuseamento de bancos de dados relacionais. Ler o √∫ltimo padr√£o (ANSI SQL 2016) pode ser demorado. Como posso apren√™-lo?

<p>
  <img src="../images/how-to-learn-sql.jpg" />
</p>

H√° 5 componentes da linguagem SQL:

- DDL: linguagem de defini√ß√£o de dados, como CREATE, ALTER, DROP
- DQL: linguagem de consulta de dados, como SELECT
- DML: linguagem de manipula√ß√£o de dados, como INSERT, UPDATE, DELETE
- DCL: linguagem de controle de dados, como GRANT, REVOKE
- TCL: linguagem de controle de transa√ß√µes, como COMMIT, ROLLBACK

Para um engenheiro de backend, pode ser necess√°rio saber a maior parte deles. Como um analista de dados, √© importante ter uma boa no√ß√£o do DQL. Selecione os t√≥picos que s√£o mais relevantes para voc√™.

## Cache

### Data is cached everywhere

This diagram illustrates where we cache data in a typical architecture.

<p>
  <img src="../images/where do we cache data.jpeg" style="width: 720px" />
</p>

There are **multiple layers** along the flow.

1. Client apps: HTTP responses can be cached by the browser. We request data over HTTP for the first time, and it is returned with an expiry policy in the HTTP header; we request data again, and the client app tries to retrieve the data from the browser cache first.
2. CDN: CDN caches static web resources. The clients can retrieve data from a CDN node nearby.
3. Load Balancer: The load Balancer can cache resources as well.
4. Messaging infra: Message brokers store messages on disk first, and then consumers retrieve them at their own pace. Depending on the retention policy, the data is cached in Kafka clusters for a period of time.
5. Services: There are multiple layers of cache in a service. If the data is not cached in the CPU cache, the service will try to retrieve the data from memory. Sometimes the service has a second-level cache to store data on disk.
6. Distributed Cache: Distributed cache like Redis holds key-value pairs for multiple services in memory. It provides much better read/write performance than the database.
7. Full-text Search: we sometimes need to use full-text searches like Elastic Search for document search or log search. A copy of data is indexed in the search engine as well.
8. Database: Even in the database, we have different levels of caches:

- WAL(Write-ahead Log): data is written to WAL first before building the B tree index
- Bufferpool: A memory area allocated to cache query results
- Materialized View: Pre-compute query results and store them in the database tables for better query performance
- Transaction log: record all the transactions and database updates
- Replication Log: used to record the replication state in a database cluster

### Why is Redis so fast?

There are 3 main reasons as shown in the diagram below.

<p>
  <img src="../images/why_redis_fast.jpeg" />
</p>

1. Redis is a RAM-based data store. RAM access is at least 1000 times faster than random disk access.
2. Redis leverages IO multiplexing and single-threaded execution loop for execution efficiency.
3. Redis leverages several efficient lower-level data structures.

Question: Another popular in-memory store is Memcached. Do you know the differences between Redis and Memcached?

You might have noticed the style of this diagram is different from my previous posts. Please let me know which one you prefer.

### How can Redis be used?

<p>
  <img src="../images/top-redis-use-cases.jpg" style="width: 520px" />
</p>

There is more to Redis than just caching.

Redis can be used in a variety of scenarios as shown in the diagram.

- Session

  We can use Redis to share user session data among different services.

- Cache

  We can use Redis to cache objects or pages, especially for hotspot data.

- Distributed lock

  We can use a Redis string to acquire locks among distributed services.

- Counter

  We can count how many likes or how many reads for articles.

- Rate limiter

  We can apply a rate limiter for certain user IPs.

- Global ID generator

  We can use Redis Int for global ID.

- Shopping cart

  We can use Redis Hash to represent key-value pairs in a shopping cart.

- Calculate user retention

  We can use Bitmap to represent the user login daily and calculate user retention.

- Message queue

  We can use List for a message queue.

- Ranking

  We can use ZSet to sort the articles.

### Top caching strategies

Designing large-scale systems usually requires careful consideration of caching.
Below are five caching strategies that are frequently utilized.

<p>
  <img src="../images/top_caching_strategy.jpeg" style="width: 680px" />
</p>

## Microservice architecture

### What does a typical microservice architecture look like?

<p>
  <img src="../images/typical-microservice-arch.jpg" style="width: 520px" />
</p>

The diagram below shows a typical microservice architecture.

- Load Balancer: This distributes incoming traffic across multiple backend services.
- CDN (Content Delivery Network): CDN is a group of geographically distributed servers that hold static content for faster delivery. The clients look for content in CDN first, then progress to backend services.
- API Gateway: This handles incoming requests and routes them to the relevant services. It talks to the identity provider and service discovery.
- Identity Provider: This handles authentication and authorization for users.
- Service Registry & Discovery: Microservice registration and discovery happen in this component, and the API gateway looks for relevant services in this component to talk to.
- Management: This component is responsible for monitoring the services.
- Microservices: Microservices are designed and deployed in different domains. Each domain has its own database. The API gateway talks to the microservices via REST API or other protocols, and the microservices within the same domain talk to each other using RPC (Remote Procedure Call).

Benefits of microservices:

- They can be quickly designed, deployed, and horizontally scaled.
- Each domain can be independently maintained by a dedicated team.
- Business requirements can be customized in each domain and better supported, as a result.

### Microservice Best Practices

A picture is worth a thousand words: 9 best practices for developing microservices.

<p>
  <img src="../images/microservice-best-practices.jpeg" />
</p>

When we develop microservices, we need to follow the following best practices:

1. Use separate data storage for each microservice
2. Keep code at a similar level of maturity
3. Separate build for each microservice
4. Assign each microservice with a single responsibility
5. Deploy into containers
6. Design stateless services
7. Adopt domain-driven design
8. Design micro frontend
9. Orchestrating microservices

### What tech stack is commonly used for microservices?

Below you will find a diagram showing the microservice tech stack, both for the development phase and for production.

<p>
  <img src="../images/microservice-tech.jpeg" />
</p>

‚ñ∂Ô∏è ùêèùê´ùêû-ùêèùê´ùê®ùêùùêÆùêúùê≠ùê¢ùê®ùêß

- Define API - This establishes a contract between frontend and backend. We can use Postman or OpenAPI for this.
- Development - Node.js or react is popular for frontend development, and java/python/go for backend development. Also, we need to change the configurations in the API gateway according to API definitions.
- Continuous Integration - JUnit and Jenkins for automated testing. The code is packaged into a Docker image and deployed as microservices.

‚ñ∂Ô∏è ùêèùê´ùê®ùêùùêÆùêúùê≠ùê¢ùê®ùêß

- NGinx is a common choice for load balancers. Cloudflare provides CDN (Content Delivery Network).
- API Gateway - We can use spring boot for the gateway, and use Eureka/Zookeeper for service discovery.
- The microservices are deployed on clouds. We have options among AWS, Microsoft Azure, or Google GCP.
  Cache and Full-text Search - Redis is a common choice for caching key-value pairs. Elasticsearch is used for full-text search.
- Communications - For services to talk to each other, we can use messaging infra Kafka or RPC.
- Persistence - We can use MySQL or PostgreSQL for a relational database, and Amazon S3 for object store. We can also use Cassandra for the wide-column store if necessary.
- Management & Monitoring - To manage so many microservices, the common Ops tools include Prometheus, Elastic Stack, and Kubernetes.

### Why is Kafka fast

There are many design decisions that contributed to Kafka‚Äôs performance. In this post, we‚Äôll focus on two. We think these two carried the most weight.

<p>
  <img src="../images/why_is_kafka_fast.jpeg" />
</p>

1. The first one is Kafka‚Äôs reliance on Sequential I/O.
2. The second design choice that gives Kafka its performance advantage is its focus on efficiency: zero copy principle.

The diagram illustrates how the data is transmitted between producer and consumer, and what zero-copy means.

- Step 1.1 - 1.3: Producer writes data to the disk
- Step 2: Consumer reads data without zero-copy

  2.1 The data is loaded from disk to OS cache

  2.2 The data is copied from OS cache to Kafka application

  2.3 Kafka application copies the data into the socket buffer

  2.4 The data is copied from socket buffer to network card

  2.5 The network card sends data out to the consumer

- Step 3: Consumer reads data with zero-copy

  3.1: The data is loaded from disk to OS cache
  3.2 OS cache directly copies the data to the network card via sendfile() command
  3.3 The network card sends data out to the consumer

Zero copy is a shortcut to save the multiple data copies between application context and kernel context.

## Payment systems

### How to learn payment systems?

<p>
  <img src="../images/learn-payments.jpg" />
</p>

### Why is the credit card called ‚Äúthe most profitable product in banks‚Äù? How does VISA/Mastercard make money?

The diagram below shows the economics of the credit card payment flow.

<p>
  <img src="../images/how does visa makes money.jpg" style="width: 640px" />
</p>

1.&nbsp;&nbsp;The cardholder pays a merchant $100 to buy a product.

2.&nbsp;The merchant benefits from the use of the credit card with higher sales volume and needs to compensate the issuer and the card network for providing the payment service. The acquiring bank sets a fee with the merchant, called the ‚Äúmerchant discount fee.‚Äù

3 - 4. The acquiring bank keeps $0.25 as the acquiring markup, and $1.75 is paid to the issuing bank as the interchange fee. The merchant discount fee should cover the interchange fee.

The interchange fee is set by the card network because it is less efficient for each issuing bank to negotiate fees with each merchant.

5.&nbsp;&nbsp;The card network sets up the network assessments and fees with each bank, which pays the card network for its services every month. For example, VISA charges a 0.11% assessment, plus a $0.0195 usage fee, for every swipe.

6.&nbsp;&nbsp;The cardholder pays the issuing bank for its services.

Why should the issuing bank be compensated?

- The issuer pays the merchant even if the cardholder fails to pay the issuer.
- The issuer pays the merchant before the cardholder pays the issuer.
- The issuer has other operating costs, including managing customer accounts, providing statements, fraud detection, risk management, clearing & settlement, etc.

### How does VISA work when we swipe a credit card at a merchant‚Äôs shop?

<p>
  <img src="../images/visa_payment.jpeg" />
</p>

VISA, Mastercard, and American Express act as card networks for the clearing and settling of funds. The card acquiring bank and the card issuing bank can be ‚Äì and often are ‚Äì different. If banks were to settle transactions one by one without an intermediary, each bank would have to settle the transactions with all the other banks. This is quite inefficient.

The diagram below shows VISA‚Äôs role in the credit card payment process. There are two flows involved. Authorization flow happens when the customer swipes the credit card. Capture and settlement flow happens when the merchant wants to get the money at the end of the day.

- Authorization Flow

Step 0: The card issuing bank issues credit cards to its customers.

Step 1: The cardholder wants to buy a product and swipes the credit card at the Point of Sale (POS) terminal in the merchant‚Äôs shop.

Step 2: The POS terminal sends the transaction to the acquiring bank, which has provided the POS terminal.

Steps 3 and 4: The acquiring bank sends the transaction to the card network, also called the card scheme. The card network sends the transaction to the issuing bank for approval.

Steps 4.1, 4.2 and 4.3: The issuing bank freezes the money if the transaction is approved. The approval or rejection is sent back to the acquirer, as well as the POS terminal.

- Capture and Settlement Flow

Steps 1 and 2: The merchant wants to collect the money at the end of the day, so they hit ‚Äùcapture‚Äù on the POS terminal. The transactions are sent to the acquirer in batch. The acquirer sends the batch file with transactions to the card network.

Step 3: The card network performs clearing for the transactions collected from different acquirers, and sends the clearing files to different issuing banks.

Step 4: The issuing banks confirm the correctness of the clearing files, and transfer money to the relevant acquiring banks.

Step 5: The acquiring bank then transfers money to the merchant‚Äôs bank.

Step 4: The card network clears up the transactions from different acquiring banks. Clearing is a process in which mutual offset transactions are netted, so the number of total transactions is reduced.

In the process, the card network takes on the burden of talking to each bank and receives service fees in return.

### Payment Systems Around The World Series (Part 1): Unified Payments Interface (UPI) in India

What‚Äôs UPI? UPI is an instant real-time payment system developed by the National Payments Corporation of India.

It accounts for 60% of digital retail transactions in India today.

UPI = payment markup language + standard for interoperable payments

<p>
  <img src="../images/how-does-upi-work.png"  style="width: 600px" />
</p>

## DevOps

### DevOps vs. SRE vs. Platform Engineering. What is the difference?

The concepts of DevOps, SRE, and Platform Engineering have emerged at different times and have been developed by various individuals and organizations.

<p>
  <img src="../images/devops-sre-platform.jpg" />
</p>

DevOps as a concept was introduced in 2009 by Patrick Debois and Andrew Shafer at the Agile conference. They sought to bridge the gap between software development and operations by promoting a collaborative culture and shared responsibility for the entire software development lifecycle.

SRE, or Site Reliability Engineering, was pioneered by Google in the early 2000s to address operational challenges in managing large-scale, complex systems. Google developed SRE practices and tools, such as the Borg cluster management system and the Monarch monitoring system, to improve the reliability and efficiency of their services.

Platform Engineering is a more recent concept, building on the foundation of SRE engineering. The precise origins of Platform Engineering are less clear, but it is generally understood to be an extension of the DevOps and SRE practices, with a focus on delivering a comprehensive platform for product development that supports the entire business perspective.

It's worth noting that while these concepts emerged at different times. They are all related to the broader trend of improving collaboration, automation, and efficiency in software development and operations.

### What is k8s (Kubernetes)?

K8s is a container orchestration system. It is used for container deployment and management. Its design is greatly impacted by Google‚Äôs internal system Borg.

<p>
  <img src="../images/k8s.jpeg" style="width: 680px" />
</p>

A k8s cluster consists of a set of worker machines, called nodes, that run containerized applications. Every cluster has at least one worker node.

The worker node(s) host the Pods that are the components of the application workload. The control plane manages the worker nodes and the Pods in the cluster. In production environments, the control plane usually runs across multiple computers, and a cluster usually runs multiple nodes, providing fault tolerance and high availability.

- Control Plane Components

1. API Server

   The API server talks to all the components in the k8s cluster. All the operations on pods are executed by talking to the API server.

2. Scheduler

   The scheduler watches pod workloads and assigns loads on newly created pods.

3. Controller Manager

   The controller manager runs the controllers, including Node Controller, Job Controller, EndpointSlice Controller, and ServiceAccount Controller.

4. Etcd

   etcd is a key-value store used as Kubernetes' backing store for all cluster data.

- Nodes

1. Pods

   A pod is a group of containers and is the smallest unit that k8s administers. Pods have a single IP address applied to every container within the pod.

2. Kubelet

   An agent that runs on each node in the cluster. It ensures containers are running in a Pod.

3. Kube Proxy

   Kube-proxy is a network proxy that runs on each node in your cluster. It routes traffic coming into a node from the service. It forwards requests for work to the correct containers.

### Docker vs. Kubernetes. Which one should we use?

<p>
  <img src="../images/docker-vs-k8s.jpg" style="width: 680px" />
</p>

What is Docker ?

Docker is an open-source platform that allows you to package, distribute, and run applications in isolated containers. It focuses on containerization, providing lightweight environments that encapsulate applications and their dependencies.

What is Kubernetes ?

Kubernetes, often referred to as K8s, is an open-source container orchestration platform. It provides a framework for automating the deployment, scaling, and management of containerized applications across a cluster of nodes.

How are both different from each other ?

Docker: Docker operates at the individual container level on a single operating system host.

You must manually manage each host and setting up networks, security policies, and storage for multiple related containers can be complex.

Kubernetes: Kubernetes operates at the cluster level. It manages multiple containerized applications across multiple hosts, providing automation for tasks like load balancing, scaling, and ensuring the desired state of applications.

In short, Docker focuses on containerization and running containers on individual hosts, while Kubernetes specializes in managing and orchestrating containers at scale across a cluster of hosts.

### How does Docker work?

The diagram below shows the architecture of Docker and how it works when we run ‚Äúdocker build‚Äù, ‚Äúdocker pull‚Äù
and ‚Äúdocker run‚Äù.

<p>
  <img src="../images/docker.jpg" style="width: 680px" />
</p>

There are 3 components in Docker architecture:

- Docker client

  The docker client talks to the Docker daemon.

- Docker host

  The Docker daemon listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes.

- Docker registry

  A Docker registry stores Docker images. Docker Hub is a public registry that anyone can use.

Let‚Äôs take the ‚Äúdocker run‚Äù command as an example.

1. Docker pulls the image from the registry.
1. Docker creates a new container.
1. Docker allocates a read-write filesystem to the container.
1. Docker creates a network interface to connect the container to the default network.
1. Docker starts the container.

## GIT

### How Git Commands work

To begin with, it's essential to identify where our code is stored. The common assumption is that there are only two locations - one on a remote server like Github and the other on our local machine. However, this isn't entirely accurate. Git maintains three local storages on our machine, which means that our code can be found in four places:

<p>
  <img src="../images/git-commands.png" style="width: 600px" />
</p>

- Working directory: where we edit files
- Staging area: a temporary location where files are kept for the next commit
- Local repository: contains the code that has been committed
- Remote repository: the remote server that stores the code

Most Git commands primarily move files between these four locations.

### How does Git Work?

The diagram below shows the Git workflow.

<p>
  <img src="../images/git-workflow.jpeg" style="width: 520px" />
</p>

Git is a distributed version control system.

Every developer maintains a local copy of the main repository and edits and commits to the local copy.

The commit is very fast because the operation doesn‚Äôt interact with the remote repository.

If the remote repository crashes, the files can be recovered from the local repositories.

### Git merge vs. Git rebase

What are the differences?

<p>
  <img src="../images/git-merge-git-rebase.jpeg" style="width: 680px" />
</p>

When we **merge changes** from one Git branch to another, we can use ‚Äògit merge‚Äô or ‚Äògit rebase‚Äô. The diagram below shows how the two commands work.

**Git merge**

This creates a new commit G‚Äô in the main branch. G‚Äô ties the histories of both main and feature branches.

Git merge is **non-destructive**. Neither the main nor the feature branch is changed.

**Git rebase**

Git rebase moves the feature branch histories to the head of the main branch. It creates new commits E‚Äô, F‚Äô, and G‚Äô for each commit in the feature branch.

The benefit of rebase is that it has a linear **commit history**.

Rebase can be dangerous if ‚Äúthe golden rule of git rebase‚Äù is not followed.

**The Golden Rule of Git Rebase**

Never use it on public branches!

## Cloud Services

### A nice cheat sheet of different cloud services (2023 edition)

<p>
  <img src="../images/cloud-compare.jpg" />
</p>

### What is cloud native?

Below is a diagram showing the evolution of architecture and processes since the 1980s.

<p>
  <img src="../images/cloud-native.jpeg" style="width: 640px" />
</p>

Organizations can build and run scalable applications on public, private, and hybrid clouds using cloud native technologies.

This means the applications are designed to leverage cloud features, so they are resilient to load and easy to scale.

Cloud native includes 4 aspects:

1. Development process

   This has progressed from waterfall to agile to DevOps.

2. Application Architecture

   The architecture has gone from monolithic to microservices. Each service is designed to be small, adaptive to the limited resources in cloud containers.

3. Deployment & packaging

   The applications used to be deployed on physical servers. Then around 2000, the applications that were not sensitive to latency were usually deployed on virtual servers. With cloud native applications, they are packaged into docker images and deployed in containers.

4. Application infrastructure

   The applications are massively deployed on cloud infrastructure instead of self-hosted servers.

## Developer productivity tools

### Visualize JSON files

Nested JSON files are hard to read.

**JsonCrack** generates graph diagrams from JSON files and makes them easy to read.

Additionally, the generated diagrams can be downloaded as images.

<p>
  <img src="../images/json-cracker.jpeg" />
</p>

### Automatically turn code into architecture diagrams

<p>
  <img src="../images/diagrams_as_code.jpeg" style="width: 640px" />
</p>

What does it do?

- Draw the cloud system architecture in Python code.
- Diagrams can also be rendered directly inside the Jupyter Notebooks.
- No design tools are needed.
- Supports the following providers: AWS, Azure, GCP, Kubernetes, Alibaba Cloud, Oracle Cloud, etc.

[Github repo](https://github.com/mingrammer/diagrams)

## Linux

### Linux file system explained

<p>
  <img src="../images/linux-file-systems.jpg" style="width: 680px" />
</p>

The Linux file system used to resemble an unorganized town where individuals constructed their houses wherever they pleased. However, in 1994, the Filesystem Hierarchy Standard (FHS) was introduced to bring order to the Linux file system.

By implementing a standard like the FHS, software can ensure a consistent layout across various Linux distributions. Nonetheless, not all Linux distributions strictly adhere to this standard. They often incorporate their own unique elements or cater to specific requirements.
To become proficient in this standard, you can begin by exploring. Utilize commands such as "cd" for navigation and "ls" for listing directory contents. Imagine the file system as a tree, starting from the root (/). With time, it will become second nature to you, transforming you into a skilled Linux administrator.

### 18 Most-used Linux Commands You Should Know

Linux commands are instructions for interacting with the operating system. They help manage files, directories, system processes, and many other aspects of the system. You need to become familiar with these commands in order to navigate and maintain Linux-based systems efficiently and effectively.

This diagram below shows popular Linux commands:

<p>
  <img src="../images/18 Most-Used Linux Commands You Should Know-01.jpeg" style="width: 680px" />
</p>

- ls - List files and directories
- cd - Change the current directory
- mkdir - Create a new directory
- rm - Remove files or directories
- cp - Copy files or directories
- mv - Move or rename files or directories
- chmod - Change file or directory permissions
- grep - Search for a pattern in files
- find - Search for files and directories
- tar - manipulate tarball archive files
- vi - Edit files using text editors
- cat - display the content of files
- top - Display processes and resource usage
- ps - Display processes information
- kill - Terminate a process by sending a signal
- du - Estimate file space usage
- ifconfig - Configure network interfaces
- ping - Test network connectivity between hosts

## Security

### How does HTTPS work?

Hypertext Transfer Protocol Secure (HTTPS) is an extension of the Hypertext Transfer Protocol (HTTP.) HTTPS transmits encrypted data using Transport Layer Security (TLS.) If the data is hijacked online, all the hijacker gets is binary code.

<p>
  <img src="../images/https.jpg" />
</p>

How is the data encrypted and decrypted?

Step 1 - The client (browser) and the server establish a TCP connection.

Step 2 - The client sends a ‚Äúclient hello‚Äù to the server. The message contains a set of necessary encryption algorithms (cipher suites) and the latest TLS version it can support. The server responds with a ‚Äúserver hello‚Äù so the browser knows whether it can support the algorithms and TLS version.

The server then sends the SSL certificate to the client. The certificate contains the public key, host name, expiry dates, etc. The client validates the certificate.

Step 3 - After validating the SSL certificate, the client generates a session key and encrypts it using the public key. The server receives the encrypted session key and decrypts it with the private key.

Step 4 - Now that both the client and the server hold the same session key (symmetric encryption), the encrypted data is transmitted in a secure bi-directional channel.

Why does HTTPS switch to symmetric encryption during data transmission? There are two main reasons:

1. Security: The asymmetric encryption goes only one way. This means that if the server tries to send the encrypted data back to the client, anyone can decrypt the data using the public key.

2. Server resources: The asymmetric encryption adds quite a lot of mathematical overhead. It is not suitable for data transmissions in long sessions.

### Oauth 2.0 Explained With Simple Terms.

OAuth 2.0 is a powerful and secure framework that allows different applications to securely interact with each other on behalf of users without sharing sensitive credentials.

<p>
  <img src="../images/oAuth2.jpg" />
</p>

The entities involved in OAuth are the User, the Server, and the Identity Provider (IDP).

What Can an OAuth Token Do?

When you use OAuth, you get an OAuth token that represents your identity and permissions. This token can do a few important things:

Single Sign-On (SSO): With an OAuth token, you can log into multiple services or apps using just one login, making life easier and safer.

Authorization Across Systems: The OAuth token allows you to share your authorization or access rights across various systems, so you don't have to log in separately everywhere.

Accessing User Profile: Apps with an OAuth token can access certain parts of your user profile that you allow, but they won't see everything.

Remember, OAuth 2.0 is all about keeping you and your data safe while making your online experiences seamless and hassle-free across different applications and services.

### Top 4 Forms of Authentication Mechanisms

<p>
  <img src="../images/top4-most-used-auth.jpg" />
</p>

1. SSH Keys:

   Cryptographic keys are used to access remote systems and servers securely

1. OAuth Tokens:

   Tokens that provide limited access to user data on third-party applications

1. SSL Certificates:

   Digital certificates ensure secure and encrypted communication between servers and clients

1. Credentials:

   User authentication information is used to verify and grant access to various systems and services

### Session, cookie, JWT, token, SSO, and OAuth 2.0 - what are they?

These terms are all related to user identity management. When you log into a website, you declare who you are (identification). Your identity is verified (authentication), and you are granted the necessary permissions (authorization). Many solutions have been proposed in the past, and the list keeps growing.

<p>
  <img src="../images/session.jpeg" />
</p>

From simple to complex, here is my understanding of user identity management:

- WWW-Authenticate is the most basic method. You are asked for the username and password by the browser. As a result of the inability to control the login life cycle, it is seldom used today.

- A finer control over the login life cycle is session-cookie. The server maintains session storage, and the browser keeps the ID of the session. A cookie usually only works with browsers and is not mobile app friendly.

- To address the compatibility issue, the token can be used. The client sends the token to the server, and the server validates the token. The downside is that the token needs to be encrypted and decrypted, which may be time-consuming.

- JWT is a standard way of representing tokens. This information can be verified and trusted because it is digitally signed. Since JWT contains the signature, there is no need to save session information on the server side.

- By using SSO (single sign-on), you can sign on only once and log in to multiple websites. It uses CAS (central authentication service) to maintain cross-site information.

- By using OAuth 2.0, you can authorize one website to access your information on another website.

### How to store passwords safely in the database and how to validate a password?

<p>
  <img src="../images/salt.jpg" style="width: 720px" />
</p>

**Things NOT to do**

- Storing passwords in plain text is not a good idea because anyone with internal access can see them.

- Storing password hashes directly is not sufficient because it is pruned to precomputation attacks, such as rainbow tables.

- To mitigate precomputation attacks, we salt the passwords.

**What is salt?**

According to OWASP guidelines, ‚Äúa salt is a unique, randomly generated string that is added to each password as part of the hashing process‚Äù.

**How to store a password and salt?**

1. the hash result is unique to each password.
1. The password can be stored in the database using the following format: hash(password + salt).

**How to validate a password?**

To validate a password, it can go through the following process:

1. A client enters the password.
1. The system fetches the corresponding salt from the database.
1. The system appends the salt to the password and hashes it. Let‚Äôs call the hashed value H1.
1. The system compares H1 and H2, where H2 is the hash stored in the database. If they are the same, the password is valid.

### Explaining JSON Web Token (JWT) to a 10 year old Kid

<p>
  <img src="../images/jwt.jpg" />
</p>

Imagine you have a special box called a JWT. Inside this box, there are three parts: a header, a payload, and a signature.

The header is like the label on the outside of the box. It tells us what type of box it is and how it's secured. It's usually written in a format called JSON, which is just a way to organize information using curly braces { } and colons : .

The payload is like the actual message or information you want to send. It could be your name, age, or any other data you want to share. It's also written in JSON format, so it's easy to understand and work with.
Now, the signature is what makes the JWT secure. It's like a special seal that only the sender knows how to create. The signature is created using a secret code, kind of like a password. This signature ensures that nobody can tamper with the contents of the JWT without the sender knowing about it.

When you want to send the JWT to a server, you put the header, payload, and signature inside the box. Then you send it over to the server. The server can easily read the header and payload to understand who you are and what you want to do.

### How does Google Authenticator (or other types of 2-factor authenticators) work?

Google Authenticator is commonly used for logging into our accounts when 2-factor authentication is enabled. How does it guarantee security?

Google Authenticator is a software-based authenticator that implements a two-step verification service. The diagram below provides detail.

<p>
  <img src="../images/google_authenticate.jpeg" />
</p>

There are two stages involved:

- Stage 1 - The user enables Google two-step verification.
- Stage 2 - The user uses the authenticator for logging in, etc.

Let‚Äôs look at these stages.

**Stage 1**

Steps 1 and 2: Bob opens the web page to enable two-step verification. The front end requests a secret key. The authentication service generates the secret key for Bob and stores it in the database.

Step 3: The authentication service returns a URI to the front end. The URI is composed of a key issuer, username, and secret key. The URI is displayed in the form of a QR code on the web page.

Step 4: Bob then uses Google Authenticator to scan the generated QR code. The secret key is stored in the authenticator.

**Stage 2**
Steps 1 and 2: Bob wants to log into a website with Google two-step verification. For this, he needs the password. Every 30 seconds, Google Authenticator generates a 6-digit password using TOTP (Time-based One Time Password) algorithm. Bob uses the password to enter the website.

Steps 3 and 4: The frontend sends the password Bob enters to the backend for authentication. The authentication service reads the secret key from the database and generates a 6-digit password using the same TOTP algorithm as the client.

Step 5: The authentication service compares the two passwords generated by the client and the server, and returns the comparison result to the frontend. Bob can proceed with the login process only if the two passwords match.

Is this authentication mechanism safe?

- Can the secret key be obtained by others?

  We need to make sure the secret key is transmitted using HTTPS. The authenticator client and the database store the secret key, and we need to make sure the secret keys are encrypted.

- Can the 6-digit password be guessed by hackers?
  No. The password has 6 digits, so the generated password has 1 million potential combinations. Plus, the password changes every 30 seconds. If hackers want to guess the password in 30 seconds, they need to enter 30,000 combinations per second.

## Real World Case Studies

### Netflix's Tech Stack

This post is based on research from many Netflix engineering blogs and open-source projects. If you come across any inaccuracies, please feel free to inform us.

<p>
  <img src="../images/netflix tech stack.png" style="width: 680px" />
</p>

**Mobile and web**: Netflix has adopted Swift and Kotlin to build native mobile apps. For its web application, it uses React.

**Frontend/server communication**: Netflix uses GraphQL.

**Backend services**: Netflix relies on ZUUL, Eureka, the Spring Boot framework, and other technologies.

**Databases**: Netflix utilizes EV cache, Cassandra, CockroachDB, and other databases.

**Messaging/streaming**: Netflix employs Apache Kafka and Fink for messaging and streaming purposes.

**Video storage**: Netflix uses S3 and Open Connect for video storage.

**Data processing**: Netflix utilizes Flink and Spark for data processing, which is then visualized using Tableau. Redshift is used for processing structured data warehouse information.

**CI/CD**: Netflix employs various tools such as JIRA, Confluence, PagerDuty, Jenkins, Gradle, Chaos Monkey, Spinnaker, Atlas, and more for CI/CD processes.

### Twitter Architecture 2022

Yes, this is the real Twitter architecture. It is posted by Elon Musk and redrawn by us for better readability.

<p>
  <img src="../images/twitter-arch.jpeg" />
</p>

### Evolution of Airbnb‚Äôs microservice architecture over the past 15 years

Airbnb‚Äôs microservice architecture went through 3 main stages.

<p>
  <img src="../images/airbnb_arch.jpeg" />
</p>

Monolith (2008 - 2017)

Airbnb began as a simple marketplace for hosts and guests. This is built in a Ruby on Rails application - the monolith.

What‚Äôs the challenge?

- Confusing team ownership + unowned code
- Slow deployment

Microservices (2017 - 2020)

Microservice aims to solve those challenges. In the microservice architecture, key services include:

- Data fetching service
- Business logic data service
- Write workflow service
- UI aggregation service
- Each service had one owning team

What‚Äôs the challenge?

Hundreds of services and dependencies were difficult for humans to manage.

Micro + macroservices (2020 - present)

This is what Airbnb is working on now. The micro and macroservice hybrid model focuses on the unification of APIs.

### Monorepo vs. Microrepo.

Which is the best? Why do different companies choose different options?

<p>
  <img src="../images/monorepo-microrepo.jpg" />
</p>

Monorepo isn't new; Linux and Windows were both created using Monorepo. To improve scalability and build speed, Google developed its internal dedicated toolchain to scale it faster and strict coding quality standards to keep it consistent.

Amazon and Netflix are major ambassadors of the Microservice philosophy. This approach naturally separates the service code into separate repositories. It scales faster but can lead to governance pain points later on.

Within Monorepo, each service is a folder, and every folder has a BUILD config and OWNERS permission control. Every service member is responsible for their own folder.

On the other hand, in Microrepo, each service is responsible for its repository, with the build config and permissions typically set for the entire repository.

In Monorepo, dependencies are shared across the entire codebase regardless of your business, so when there's a version upgrade, every codebase upgrades their version.

In Microrepo, dependencies are controlled within each repository. Businesses choose when to upgrade their versions based on their own schedules.

Monorepo has a standard for check-ins. Google's code review process is famously known for setting a high bar, ensuring a coherent quality standard for Monorepo, regardless of the business.

Microrepo can either set its own standard or adopt a shared standard by incorporating the best practices. It can scale faster for business, but the code quality might be a bit different.
Google engineers built Bazel, and Meta built Buck. There are other open-source tools available, including Nx, Lerna, and others.

Over the years, Microrepo has had more supported tools, including Maven and Gradle for Java, NPM for NodeJS, and CMake for C/C++, among others.

### How will you design the Stack Overflow website?

If your answer is on-premise servers and monolith (on the bottom of the following image), you would likely fail the interview, but that's how it is built in reality!

<p>
  <img src="../images/stackoverflow.jpg" />
</p>

**What people think it should look like**

The interviewer is probably expecting something like the top portion of the picture.

- Microservice is used to decompose the system into small components.
- Each service has its own database. Use cache heavily.
- The service is sharded.
- The services talk to each other asynchronously through message queues.
- The service is implemented using Event Sourcing with CQRS.
- Showing off knowledge in distributed systems such as eventual consistency, CAP theorem, etc.

**What it actually is**

Stack Overflow serves all the traffic with only 9 on-premise web servers, and it‚Äôs on monolith! It has its own servers and does not run on the cloud.

This is contrary to all our popular beliefs these days.

### Why did Amazon Prime Video monitoring move from serverless to monolithic? How can it save 90% cost?

The diagram below shows the architecture comparison before and after the migration.

<p>
  <img src="../images/serverless-to-monolithic.jpeg" />
</p>

What is Amazon Prime Video Monitoring Service?

Prime Video service needs to monitor the quality of thousands of live streams. The monitoring tool automatically analyzes the streams in real time and identifies quality issues like block corruption, video freeze, and sync problems. This is an important process for customer satisfaction.

There are 3 steps: media converter, defect detector, and real-time notification.

- What is the problem with the old architecture?

  The old architecture was based on Amazon Lambda, which was good for building services quickly. However, it was not cost-effective when running the architecture at a high scale. The two most expensive operations are:

1. The orchestration workflow - AWS step functions charge users by state transitions and the orchestration performs multiple state transitions every second.

2. Data passing between distributed components - the intermediate data is stored in Amazon S3 so that the next stage can download. The download can be costly when the volume is high.

- Monolithic architecture saves 90% cost

  A monolithic architecture is designed to address the cost issues. There are still 3 components, but the media converter and defect detector are deployed in the same process, saving the cost of passing data over the network. Surprisingly, this approach to deployment architecture change led to 90% cost savings!

This is an interesting and unique case study because microservices have become a go-to and fashionable choice in the tech industry. It's good to see that we are having more discussions about evolving the architecture and having more honest discussions about its pros and cons. Decomposing components into distributed microservices comes with a cost.

- What did Amazon leaders say about this?

  Amazon CTO Werner Vogels: ‚ÄúBuilding **evolvable software systems** is a strategy, not a religion. And revisiting your architecture with an open mind is a must.‚Äù

Ex Amazon VP Sustainability Adrian Cockcroft: ‚ÄúThe Prime Video team had followed a path I call **Serverless First**‚Ä¶I don‚Äôt advocate **Serverless Only**‚Äù.

### How does Disney Hotstar capture 5 Billion Emojis during a tournament?

<p>
  <img src="../images/hotstar_emojis.jpeg" style="width: 720px" />
</p>

1. Clients send emojis through standard HTTP requests. You can think of Golang Service as a typical Web Server. Golang is chosen because it supports concurrency well. Threads in Golang are lightweight.

2. Since the write volume is very high, Kafka (message queue) is used as a buffer.

3. Emoji data are aggregated by a streaming processing service called Spark. It aggregates data every 2 seconds, which is configurable. There is a trade-off to be made based on the interval. A shorter interval means emojis are delivered to other clients faster but it also means more computing resources are needed.

4. Aggregated data is written to another Kafka.

5. The PubSub consumers pull aggregated emoji data from Kafka.

6. Emojis are delivered to other clients in real-time through the PubSub infrastructure. The PubSub infrastructure is interesting. Hotstar considered the following protocols: Socketio, NATS, MQTT, and gRPC, and settled with MQTT.

A similar design is adopted by LinkedIn which streams a million likes/sec.

### How Discord Stores Trillions Of Messages

The diagram below shows the evolution of message storage at Discord:

<p>
  <img src="../images/discord-store-messages.jpg" />
</p>

MongoDB ‚û°Ô∏è Cassandra ‚û°Ô∏è ScyllaDB

In 2015, the first version of Discord was built on top of a single MongoDB replica. Around Nov 2015, MongoDB stored 100 million messages and the RAM couldn‚Äôt hold the data and index any longer. The latency became unpredictable. Message storage needs to be moved to another database. Cassandra was chosen.

In 2017, Discord had 12 Cassandra nodes and stored billions of messages.

At the beginning of 2022, it had 177 nodes with trillions of messages. At this point, latency was unpredictable, and maintenance operations became too expensive to run.

There are several reasons for the issue:

- Cassandra uses the LSM tree for the internal data structure. The reads are more expensive than the writes. There can be many concurrent reads on a server with hundreds of users, resulting in hotspots.
- Maintaining clusters, such as compacting SSTables, impacts performance.
- Garbage collection pauses would cause significant latency spikes

ScyllaDB is Cassandra compatible database written in C++. Discord redesigned its architecture to have a monolithic API, a data service written in Rust, and ScyllaDB-based storage.

The p99 read latency in ScyllaDB is 15ms compared to 40-125ms in Cassandra. The p99 write latency is 5ms compared to 5-70ms in Cassandra.

### How do video live streamings work on YouTube, TikTok live, or Twitch?

Live streaming differs from regular streaming because the video content is sent via the internet in real-time, usually with a latency of just a few seconds.

The diagram below explains what happens behind the scenes to make this possible.

<p>
  <img src="../images/live_streaming_updated.jpg" style="width: 640px" />
</p>

Step 1: The raw video data is captured by a microphone and camera. The data is sent to the server side.

Step 2: The video data is compressed and encoded. For example, the compressing algorithm separates the background and other video elements. After compression, the video is encoded to standards such as H.264. The size of the video data is much smaller after this step.

Step 3: The encoded data is divided into smaller segments, usually seconds in length, so it takes much less time to download or stream.

Step 4: The segmented data is sent to the streaming server. The streaming server needs to support different devices and network conditions. This is called ‚ÄòAdaptive Bitrate Streaming.‚Äô This means we need to produce multiple files at different bitrates in steps 2 and 3.

Step 5: The live streaming data is pushed to edge servers supported by CDN (Content Delivery Network.) Millions of viewers can watch the video from an edge server nearby. CDN significantly lowers data transmission latency.

Step 6: The viewers‚Äô devices decode and decompress the video data and play the video in a video player.

Steps 7 and 8: If the video needs to be stored for replay, the encoded data is sent to a storage server, and viewers can request a replay from it later.

Standard protocols for live streaming include:

- RTMP (Real-Time Messaging Protocol): This was originally developed by Macromedia to transmit data between a Flash player and a server. Now it is used for streaming video data over the internet. Note that video conferencing applications like Skype use RTC (Real-Time Communication) protocol for lower latency.
- HLS (HTTP Live Streaming): It requires the H.264 or H.265 encoding. Apple devices accept only HLS format.
- DASH (Dynamic Adaptive Streaming over HTTP): DASH does not support Apple devices.
- Both HLS and DASH support adaptive bitrate streaming.

## License

<p xmlns:cc="http://creativecommons.org/ns#" >This work is licensed under <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-ND 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1"></a></p>
